{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "\n",
    "from sklearn.datasets import load_boston, load_iris, load_wine\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Target names: ['class_0' 'class_1' 'class_2']\n",
      "Shape: (178, 13)\n"
     ]
    }
   ],
   "source": [
    "data = load_wine()\n",
    "print(\"Feature names:\", data.feature_names)\n",
    "print(\"Target names:\", data.target_names)\n",
    "print(\"Shape:\", data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            params  mean_fit_time  \\\n",
      "1     {'criterion': 'gini', 'min_samples_leaf': 3}       0.000704   \n",
      "2     {'criterion': 'gini', 'min_samples_leaf': 5}       0.001102   \n",
      "0     {'criterion': 'gini', 'min_samples_leaf': 1}       0.000964   \n",
      "3  {'criterion': 'entropy', 'min_samples_leaf': 1}       0.001164   \n",
      "4  {'criterion': 'entropy', 'min_samples_leaf': 3}       0.000997   \n",
      "5  {'criterion': 'entropy', 'min_samples_leaf': 5}       0.001414   \n",
      "\n",
      "   mean_score_time  mean_test_score  \n",
      "1         0.000212         0.936620  \n",
      "2         0.000210         0.936620  \n",
      "0         0.000467         0.922535  \n",
      "3         0.000248         0.908451  \n",
      "4         0.000543         0.908451  \n",
      "5         0.000435         0.901408  \n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "parameters = {'criterion': ('gini', 'entropy'), 'min_samples_leaf':[1, 3, 5]}\n",
    "clf = GridSearchCV(dt, parameters, cv=5, return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "print(cv_results[['params', 'mean_fit_time', 'mean_score_time', 'mean_test_score']].sort_values(by='mean_test_score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      params  mean_fit_time  mean_score_time  \\\n",
      "0   {'fit_intercept': True, 'penalty': 'l1'}       0.008740         0.000365   \n",
      "2  {'fit_intercept': False, 'penalty': 'l1'}       0.008785         0.000200   \n",
      "1   {'fit_intercept': True, 'penalty': 'l2'}       0.001618         0.000567   \n",
      "3  {'fit_intercept': False, 'penalty': 'l2'}       0.002788         0.000200   \n",
      "\n",
      "   mean_test_score  \n",
      "0         0.943662  \n",
      "2         0.943662  \n",
      "1         0.936620  \n",
      "3         0.936620  \n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "parameters = {'fit_intercept': (True, False), 'penalty':('l1', 'l2')}\n",
    "clf = GridSearchCV(lr, parameters, cv=5, return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "print(cv_results[['params', 'mean_fit_time', 'mean_score_time', 'mean_test_score']].sort_values(by='mean_test_score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       params  mean_fit_time  mean_score_time  \\\n",
      "0    {'n_neighbors': 1, 'weights': 'uniform'}       0.000992         0.000962   \n",
      "1   {'n_neighbors': 1, 'weights': 'distance'}       0.000863         0.000928   \n",
      "3   {'n_neighbors': 3, 'weights': 'distance'}       0.000613         0.000691   \n",
      "5   {'n_neighbors': 5, 'weights': 'distance'}       0.000405         0.000545   \n",
      "7  {'n_neighbors': 10, 'weights': 'distance'}       0.000618         0.000985   \n",
      "4    {'n_neighbors': 5, 'weights': 'uniform'}       0.000321         0.001191   \n",
      "6   {'n_neighbors': 10, 'weights': 'uniform'}       0.000426         0.001188   \n",
      "2    {'n_neighbors': 3, 'weights': 'uniform'}       0.000586         0.000825   \n",
      "\n",
      "   mean_test_score  \n",
      "0         0.760563  \n",
      "1         0.760563  \n",
      "3         0.753521  \n",
      "5         0.753521  \n",
      "7         0.746479  \n",
      "4         0.697183  \n",
      "6         0.697183  \n",
      "2         0.669014  \n"
     ]
    }
   ],
   "source": [
    "nbrs = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':[1, 3, 5, 10], 'weights': ('uniform', 'distance')}\n",
    "clf = GridSearchCV(nbrs, parameters, cv=5, return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "print(cv_results[['params', 'mean_fit_time', 'mean_score_time', 'mean_test_score']].sort_values(by='mean_test_score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CobyLU\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               params  mean_fit_time  \\\n",
      "8   {'hidden_layer_sizes': 150, 'learning_rate_ini...       0.052262   \n",
      "9   {'hidden_layer_sizes': 150, 'learning_rate_ini...       0.013589   \n",
      "6   {'hidden_layer_sizes': 100, 'learning_rate_ini...       0.034115   \n",
      "14  {'hidden_layer_sizes': (100, 50), 'learning_ra...       0.012175   \n",
      "5   {'hidden_layer_sizes': 100, 'learning_rate_ini...       0.032898   \n",
      "0   {'hidden_layer_sizes': 50, 'learning_rate_init...       0.008187   \n",
      "4   {'hidden_layer_sizes': 100, 'learning_rate_ini...       0.006209   \n",
      "2   {'hidden_layer_sizes': 50, 'learning_rate_init...       0.018190   \n",
      "3   {'hidden_layer_sizes': 50, 'learning_rate_init...       0.005799   \n",
      "10  {'hidden_layer_sizes': 150, 'learning_rate_ini...       0.010582   \n",
      "12  {'hidden_layer_sizes': (100, 50), 'learning_ra...       0.008174   \n",
      "15  {'hidden_layer_sizes': (100, 50), 'learning_ra...       0.009559   \n",
      "1   {'hidden_layer_sizes': 50, 'learning_rate_init...       0.039428   \n",
      "11  {'hidden_layer_sizes': 150, 'learning_rate_ini...       0.009777   \n",
      "13  {'hidden_layer_sizes': (100, 50), 'learning_ra...       0.014171   \n",
      "7   {'hidden_layer_sizes': 100, 'learning_rate_ini...       0.007776   \n",
      "\n",
      "    mean_score_time  mean_test_score  \n",
      "8          0.000398         0.471831  \n",
      "9          0.000567         0.401408  \n",
      "6          0.000798         0.387324  \n",
      "14         0.000199         0.380282  \n",
      "5          0.000805         0.373239  \n",
      "0          0.000200         0.359155  \n",
      "4          0.000464         0.359155  \n",
      "2          0.000000         0.345070  \n",
      "3          0.000584         0.345070  \n",
      "10         0.000399         0.345070  \n",
      "12         0.000986         0.345070  \n",
      "15         0.000825         0.345070  \n",
      "1          0.000483         0.338028  \n",
      "11         0.000590         0.309859  \n",
      "13         0.000779         0.302817  \n",
      "7          0.000432         0.288732  \n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='sgd', learning_rate='constant')\n",
    "parameters = {'hidden_layer_sizes':[(50), (100), (150), (100, 50)], 'learning_rate_init': [0.0005, 0.001, 0.005, 0.01]}\n",
    "clf = GridSearchCV(mlp, parameters, cv=5, return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "print(cv_results[['params', 'mean_fit_time', 'mean_score_time', 'mean_test_score']].sort_values(by='mean_test_score', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               params  mean_fit_time  \\\n",
      "15  {'base_estimator__criterion': 'gini', 'base_es...       0.131209   \n",
      "71  {'base_estimator__criterion': 'entropy', 'base...       0.098376   \n",
      "54  {'base_estimator__criterion': 'entropy', 'base...       0.043065   \n",
      "63  {'base_estimator__criterion': 'entropy', 'base...       0.115075   \n",
      "79  {'base_estimator__criterion': 'entropy', 'base...       0.098432   \n",
      "75  {'base_estimator__criterion': 'entropy', 'base...       0.123875   \n",
      "31  {'base_estimator__criterion': 'gini', 'base_es...       0.100545   \n",
      "35  {'base_estimator__criterion': 'gini', 'base_es...       0.115530   \n",
      "23  {'base_estimator__criterion': 'gini', 'base_es...       0.104104   \n",
      "27  {'base_estimator__criterion': 'gini', 'base_es...       0.122681   \n",
      "\n",
      "    mean_score_time  mean_test_score  \n",
      "15         0.007412         0.992958  \n",
      "71         0.006735         0.992958  \n",
      "54         0.002815         0.985915  \n",
      "63         0.007850         0.985915  \n",
      "79         0.006713         0.978873  \n",
      "75         0.005776         0.978873  \n",
      "31         0.006983         0.978873  \n",
      "35         0.005760         0.978873  \n",
      "23         0.006987         0.971831  \n",
      "27         0.006588         0.964789  \n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "parameters = {'base_estimator__criterion':['gini', 'entropy'], \n",
    "              'base_estimator__splitter': ['best', 'random'],\n",
    "              'base_estimator__min_samples_leaf': [1, 3, 5, 10, 20],\n",
    "              'n_estimators': [5, 10, 20, 50]}\n",
    "clf = GridSearchCV(ada, parameters, cv=5, return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "print(cv_results[['params', 'mean_fit_time', 'mean_score_time', 'mean_test_score']].sort_values(by='mean_test_score', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           params  mean_test_score\n",
      "14   {'min_samples_leaf': 5, 'n_estimators': 100}         0.978873\n",
      "0      {'min_samples_leaf': 1, 'n_estimators': 5}         0.957746\n",
      "7     {'min_samples_leaf': 3, 'n_estimators': 20}         0.957746\n",
      "23   {'min_samples_leaf': 20, 'n_estimators': 50}         0.957746\n",
      "19  {'min_samples_leaf': 10, 'n_estimators': 100}         0.957746\n",
      "9    {'min_samples_leaf': 3, 'n_estimators': 100}         0.957746\n",
      "8     {'min_samples_leaf': 3, 'n_estimators': 50}         0.957746\n",
      "12    {'min_samples_leaf': 5, 'n_estimators': 20}         0.957746\n",
      "24  {'min_samples_leaf': 20, 'n_estimators': 100}         0.957746\n",
      "3     {'min_samples_leaf': 1, 'n_estimators': 50}         0.957746\n",
      "4    {'min_samples_leaf': 1, 'n_estimators': 100}         0.957746\n",
      "2     {'min_samples_leaf': 1, 'n_estimators': 20}         0.950704\n",
      "1     {'min_samples_leaf': 1, 'n_estimators': 10}         0.950704\n",
      "18   {'min_samples_leaf': 10, 'n_estimators': 50}         0.950704\n",
      "17   {'min_samples_leaf': 10, 'n_estimators': 20}         0.943662\n",
      "22   {'min_samples_leaf': 20, 'n_estimators': 20}         0.943662\n",
      "6     {'min_samples_leaf': 3, 'n_estimators': 10}         0.943662\n",
      "5      {'min_samples_leaf': 3, 'n_estimators': 5}         0.943662\n",
      "13    {'min_samples_leaf': 5, 'n_estimators': 50}         0.943662\n",
      "11    {'min_samples_leaf': 5, 'n_estimators': 10}         0.943662\n",
      "10     {'min_samples_leaf': 5, 'n_estimators': 5}         0.943662\n",
      "21   {'min_samples_leaf': 20, 'n_estimators': 10}         0.936620\n",
      "16   {'min_samples_leaf': 10, 'n_estimators': 10}         0.936620\n",
      "15    {'min_samples_leaf': 10, 'n_estimators': 5}         0.929577\n",
      "20    {'min_samples_leaf': 20, 'n_estimators': 5}         0.922535\n"
     ]
    }
   ],
   "source": [
    "gbm = GradientBoostingClassifier()\n",
    "parameters = {'min_samples_leaf': [1, 3, 5, 10, 20],\n",
    "              'n_estimators': [5, 10, 20, 50, 100]}\n",
    "clf = GridSearchCV(gbm, parameters, cv=5, return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "print(cv_results[['params', 'mean_test_score']].sort_values(by='mean_test_score', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
