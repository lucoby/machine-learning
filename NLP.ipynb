{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP on Academic Knowledge and Skills (AKS)\n",
    "\n",
    "Gwinnett’s curriculum for grades K–12 is called the Academic Knowledge and Skills (AKS) and is aligned to the state-adopted Georgia Standards of Excellence in Language Arts (K-12), Mathematics (K-12), and literacy standards for Science, Social Studies, and Technical Education for middle and high school students. The Georgia Performance Standards (GPS) are in place for other content areas. Gwinnett’s AKS is a rigorous curriculum that prepares students for college and 21st century careers in a globally competitive future.\n",
    "\n",
    "The AKS for each grade level spells out the essential concepts students are expected to know and skills they should acquire in that grade or subject. The AKS offers a solid base on which teachers build rich learning experiences. Teachers use curriculum guides, technology, and  instructional resources to teach the AKS and to make sure every student is learning to his or her potential. \n",
    "\n",
    "[1. GCPS Academic Knowledge and Skills (AKS)](https://publish.gwinnett.k12.ga.us/gcps/myhome/public/parents/content/general-info/aks)\n",
    "\n",
    "## Reading in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.metrics import pairwise\n",
    "from scipy import sparse\n",
    "import spacy\n",
    "\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1415, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Director</th>\n",
       "      <th>Low Grade</th>\n",
       "      <th>High Grade</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Course</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Strand Text</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Reference Code</th>\n",
       "      <th>Reference Key</th>\n",
       "      <th>Type1</th>\n",
       "      <th>AKS number</th>\n",
       "      <th>IOA number</th>\n",
       "      <th>AKS text</th>\n",
       "      <th>IOA text</th>\n",
       "      <th>AKS or IOA</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>GDOEKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Mathematics - K</td>\n",
       "      <td>A</td>\n",
       "      <td>Counting and Cardinality</td>\n",
       "      <td>1</td>\n",
       "      <td>KMA</td>\n",
       "      <td>KMA_A2012-1</td>\n",
       "      <td>AKS</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>count to 100 by ones and tens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>count to 100 by ones and tens</td>\n",
       "      <td>GSE</td>\n",
       "      <td>MCCK.CC.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Mathematics - K</td>\n",
       "      <td>A</td>\n",
       "      <td>Counting and Cardinality</td>\n",
       "      <td>2</td>\n",
       "      <td>KMA</td>\n",
       "      <td>KMA_A2012-2</td>\n",
       "      <td>AKS</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>count forward by ones, beginning from a given ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>count forward by ones, beginning from a given ...</td>\n",
       "      <td>GSE</td>\n",
       "      <td>MCCK.CC.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Mathematics - K</td>\n",
       "      <td>A</td>\n",
       "      <td>Counting and Cardinality</td>\n",
       "      <td>3</td>\n",
       "      <td>KMA</td>\n",
       "      <td>KMA_A2012-3</td>\n",
       "      <td>AKS</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>write numerals from 0 to 20 and represent a nu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>write numerals from 0 to 20 and represent a nu...</td>\n",
       "      <td>GSE</td>\n",
       "      <td>MCCK.CC.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Mathematics - K</td>\n",
       "      <td>A</td>\n",
       "      <td>Counting and Cardinality</td>\n",
       "      <td>4</td>\n",
       "      <td>KMA</td>\n",
       "      <td>KMA_A2012-4</td>\n",
       "      <td>AKS</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrate the relationship between numbers a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrate the relationship between numbers a...</td>\n",
       "      <td>GSE</td>\n",
       "      <td>MCCK.CC.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Mathematics - K</td>\n",
       "      <td>A</td>\n",
       "      <td>Counting and Cardinality</td>\n",
       "      <td>5</td>\n",
       "      <td>KMA</td>\n",
       "      <td>KMA_A2012-5</td>\n",
       "      <td>AKS</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>count objects by stating number names in the s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>count objects by stating number names in the s...</td>\n",
       "      <td>GSE</td>\n",
       "      <td>MCCK.CC.4_a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Director Low Grade High Grade      Subject           Course Strand  \\\n",
       "0  Mathematics         K          K  Mathematics  Mathematics - K      A   \n",
       "1  Mathematics         K          K  Mathematics  Mathematics - K      A   \n",
       "2  Mathematics         K          K  Mathematics  Mathematics - K      A   \n",
       "3  Mathematics         K          K  Mathematics  Mathematics - K      A   \n",
       "4  Mathematics         K          K  Mathematics  Mathematics - K      A   \n",
       "\n",
       "                Strand Text  Sequence Reference Code Reference Key Type1  \\\n",
       "0  Counting and Cardinality         1            KMA   KMA_A2012-1   AKS   \n",
       "1  Counting and Cardinality         2            KMA   KMA_A2012-2   AKS   \n",
       "2  Counting and Cardinality         3            KMA   KMA_A2012-3   AKS   \n",
       "3  Counting and Cardinality         4            KMA   KMA_A2012-4   AKS   \n",
       "4  Counting and Cardinality         5            KMA   KMA_A2012-5   AKS   \n",
       "\n",
       "   AKS number IOA number                                           AKS text  \\\n",
       "0           1        NaN                      count to 100 by ones and tens   \n",
       "1           2        NaN  count forward by ones, beginning from a given ...   \n",
       "2           3        NaN  write numerals from 0 to 20 and represent a nu...   \n",
       "3           4        NaN  demonstrate the relationship between numbers a...   \n",
       "4           5        NaN  count objects by stating number names in the s...   \n",
       "\n",
       "   IOA text                                         AKS or IOA Correlation  \\\n",
       "0       NaN                      count to 100 by ones and tens         GSE   \n",
       "1       NaN  count forward by ones, beginning from a given ...         GSE   \n",
       "2       NaN  write numerals from 0 to 20 and represent a nu...         GSE   \n",
       "3       NaN  demonstrate the relationship between numbers a...         GSE   \n",
       "4       NaN  count objects by stating number names in the s...         GSE   \n",
       "\n",
       "       GDOEKey  \n",
       "0    MCCK.CC.1  \n",
       "1    MCCK.CC.2  \n",
       "2    MCCK.CC.3  \n",
       "3    MCCK.CC.4  \n",
       "4  MCCK.CC.4_a  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_aks = pd.read_excel('17-18 AKS New.xlsx', sheetname='MA')\n",
    "print(math_aks.shape)\n",
    "math_aks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        count to 100 by ones and tens\n",
       "1    count forward by ones, beginning from a given ...\n",
       "2    write numerals from 0 to 20 and represent a nu...\n",
       "3    demonstrate the relationship between numbers a...\n",
       "4    count objects by stating number names in the s...\n",
       "Name: AKS text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = math_aks['AKS text']\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 1415\n",
    "n_features = 700\n",
    "n_components = 20\n",
    "n_top_words = 10\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \"; \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                                   ngram_range=(1,2), \n",
    "                                   max_df=0.95, \n",
    "                                   min_df=2,\n",
    "                                   stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names() \n",
    "tf_vectorizer = CountVectorizer(ngram_range=(1,2), \n",
    "                                max_df=0.95, \n",
    "                                min_df=2,\n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: solve problems; problems; solve; apply; appropriate; appropriate strategies; strategies solve; adapt; adapt variety; variety appropriate\n",
      "Topic #1: functions; inverse; inverse functions; exponential; exponential functions; trigonometric; apply; trigonometric functions; linear; linear functions\n",
      "Topic #2: add; subtract; add subtract; operations; properties operations; strategies; properties; multiply; numbers; addition\n",
      "Topic #3: ideas; mathematical ideas; mathematical; connections mathematical; connections; recognize use; use connections; use; recognize; coherent\n",
      "Topic #4: showing; functions showing; behavior; end behavior; end; functions; graph exponential; intercepts end; showing intercepts; graph\n",
      "Topic #5: equations; solve; variable; quadratic; linear; equations variable; solve quadratic; quadratic equations; linear equations; solutions\n",
      "Topic #6: expression; reveal; equivalent; different; reveal explain; expression reveal; function; defined expression; function defined; different equivalent\n",
      "Topic #7: evaluate mathematical; evaluate; mathematical; mathematical arguments; arguments; investigate; proofs; arguments proofs; develop evaluate; analyze evaluate\n",
      "Topic #8: mathematical problems; world; real world; real; world mathematical; mathematical; solve real; problems; solve; rational numbers\n",
      "Topic #9: mathematics; mathematics contexts; apply mathematics; outside mathematics; recognize apply; outside; contexts; recognize; contexts outside; aspects\n",
      "Topic #10: function; relationship; relationship quantities; quantities; describes; key; function describes; describes relationship; write function; graph\n",
      "Topic #11: terms; interpret; context; terms context; terms factors; expressions; expressions represent; quantity terms; represent quantity; interpret expressions\n",
      "Topic #12: problem solving; solving; problem; mathematical; monitor reflect; process mathematical; monitor; reflect process; reflect; knowledge problem\n",
      "Topic #13: distribution; data; data distribution; population; shape; center; mean; sample; sets; data sets\n",
      "Topic #14: number; fraction; line; number line; fractions; represent; recognize; numbers; visual; fraction number\n",
      "Topic #15: graph; graph functions; using technology; technology; features graph; graph hand; functions expressed; key features; key; hand\n",
      "Topic #16: proof; types reasoning; select use; use various; reasoning methods; methods proof; various types; types; methods; select\n",
      "Topic #17: thinking; mathematical thinking; communicate; communicate mathematical; coherently; peers teachers; peers; teachers; thinking coherently; coherently peers\n",
      "Topic #18: use representations; physical social; mathematical phenomena; representations model; interpret physical; social mathematical; model interpret; physical; social; representations\n",
      "Topic #19: vectors; determine; calculate; intersecting; subtract vectors; integrate; acceleration; magnitude; angle; vector\n",
      "\n",
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: solve; problems; use; solve problems; using; represent; students; including; equations; involving\n",
      "Topic #1: function; functions; linear; graph; exponential; determine; table; exponential functions; given; interval\n",
      "Topic #2: numbers; number; subtract; operations; add; using; multiply; rational; add subtract; strategies\n",
      "Topic #3: use; mathematical; explain; mathematical ideas; make; ideas; recognize; evaluate; evaluate mathematical; investigate\n",
      "Topic #4: functions; apply; trigonometric; trigonometric functions; graph; showing; inverse; end; inverse functions; logarithmic\n",
      "Topic #5: equations; linear; variable; variables; solutions; linear equations; quadratic; represent; solve quadratic; inequalities\n",
      "Topic #6: expression; properties; function; reveal; equivalent; expression reveal; represented; forms; defined expression; problems arise\n",
      "Topic #7: data; interpret; probabilities; probability; using; distribution; appropriate; scatter; analyze; model\n",
      "Topic #8: real; world; real world; world mathematical; problems; mathematical; mathematical problems; solve; solve real; solving\n",
      "Topic #9: line; point; points; apply; parallel; properties; angles; lines; distance; prove\n",
      "Topic #10: quantities; relationship; positive; write; function; relationship quantities; tables; negative; relationships; positive negative\n",
      "Topic #11: interpret; terms; recognize; context; mathematics; terms context; contexts; factors; quantity; relative\n",
      "Topic #12: vector; problem; understand; determine; solving; given; process; problem solving; angle; recognize\n",
      "Topic #13: sample; data; random; population; distribution; distinguish; space; sampling; numerical; mean\n",
      "Topic #14: fraction; using; number; fractions; explain; model; recognize; visual; problem; size\n",
      "Topic #15: using; technology; using technology; identify; values; properties; include; simple; shapes; value\n",
      "Topic #16: students; use; theorem; types; reasoning; proof; apply; various; fundamental; value\n",
      "Topic #17: plane; use; thinking; dimensional; coordinates; organize; figures; communicate mathematical; triangles; communicate\n",
      "Topic #18: given; square; equation; number; use; objects; numbers; terms; form; sequence\n",
      "Topic #19: vectors; unit; volume; area; calculate; use; formulas; length; using; units\n",
      "\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: data; units; distribution; use; interpret; measurement; scale; sets; context; way\n",
      "Topic #1: sampling; population; treatment; treatment effects; effects; understand; distribution; difference treatment; sampling distribution; significant\n",
      "Topic #2: given; probability; unit; rate; conditional; quantity; conditional probability; relative; equation; given number\n",
      "Topic #3: functions; represented; properties functions; verbal; compare; properties; compare properties; functions represented; algebraic; algebraically\n",
      "Topic #4: cos; sin; sin cos; place; time; represents; tan; cos tan; digit; multi\n",
      "Topic #5: event; probability; indicates; likely; near; likelihood; near indicates; unlikely; probability near; compound event\n",
      "Topic #6: solutions solutions; math; tens tens; terminal point; measure; modeling contexts; model periodic; times quantity; quantities use; connections mathematical\n",
      "Topic #7: using; numbers; use; number; vector; represent; vectors; probabilities; 30; value\n",
      "Topic #8: sample; input; output; function; language; set; space; sample space; explain; use\n",
      "Topic #9: number; line; number line; represent; numbers; recognize; point; write; segment; objects\n",
      "Topic #10: shares; place; words; use; words chapter; book; science; grade science; grade; measures\n",
      "Topic #11: statistical; question; planning; statistical question; related; retirement planning; retirement; stock; mathematical; students\n",
      "Topic #12: compare; ones; using; comparisons; record; numbers; symbols; results comparisons; results; problem\n",
      "Topic #13: solve; equations; problems; use; mathematical; students; using; apply; linear; solve problems\n",
      "Topic #14: lengths; volume; unit; rectangular; area; edge lengths; edge; prism; right rectangular; height\n",
      "Topic #15: function; using; determine; graph; model; appropriate; determine appropriate; simulation; functions; decide\n",
      "Topic #16: probability; distinguish; attributes; selected; values; causation; probabilities; matrices; assigning; outcomes\n",
      "Topic #17: properties; use; apply; numbers; functions; using; explain; number; rational; expression\n",
      "Topic #18: create; simulated; simulated sampling; sampling; sampling distribution; distribution; using; angles; develop; technology\n",
      "Topic #19: mathematical thinking; thinking; mathematical; communicate; communicate mathematical; peers; coherently; peers teachers; teachers; thinking coherently\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "nmf_fn = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5)\n",
    "nmf_fn_topics = nmf_fn.fit(tfidf)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf_fn, tfidf_feature_names, n_top_words)\n",
    "\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "nmf_kl = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5)\n",
    "nmf_kl_topics = nmf_kl.fit(tfidf)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf_kl, tfidf_feature_names, n_top_words)\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=10,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "lda_topics = lda.fit_transform(tf)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document similarity with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                (count, to, 100, by, ones, and, tens)\n",
      "1    (count, forward, by, ones, ,, beginning, from,...\n",
      "2    (write, numerals, from, 0, to, 20, and, repres...\n",
      "3    (demonstrate, the, relationship, between, numb...\n",
      "4    (count, objects, by, stating, number, names, i...\n",
      "Name: AKS text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "spacy_corpus = corpus.apply(nlp)\n",
    "print(spacy_corpus.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spacy_similarity = np.zeros((len(spacy_corpus), len(spacy_corpus)))\n",
    "for (i, doc) in enumerate(spacy_corpus):\n",
    "    for (j, other_doc) in enumerate(spacy_corpus):\n",
    "        spacy_similarity[i, j] = doc.similarity(other_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_similar_phrases(pairwise_similarity, phrases, phrase_num):\n",
    "    phrase = phrases[phrase_num]\n",
    "    pairwise_phrase = (pairwise_similarity - np.eye(len(phrases)))[phrase_num].tolist()\n",
    "    phrase_scores = [pair for pair in zip(range(0, len(phrases)), phrases, pairwise_phrase) if pair[2] > 0]\n",
    "    phrase_scores = sorted(phrase_scores, key=lambda t: t[2] * -1)[:10]\n",
    "    return (phrase, phrase_scores)\n",
    "\n",
    "def get_least_similar_phrases(pairwise_similarity, phrases, phrase_num):\n",
    "    phrase = phrases[phrase_num]\n",
    "    pairwise_phrase = (pairwise_similarity - np.eye(len(phrases)))[phrase_num].tolist()\n",
    "    phrase_scores = [pair for pair in zip(range(0, len(phrases)), phrases, pairwise_phrase) if pair[2] > 0]\n",
    "    phrase_scores = sorted(phrase_scores, key=lambda t: t[2])[:10]\n",
    "    return (phrase, phrase_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase: compare two fractions with the same numerator or the same denominator by reasoning about their size; recognize that comparisons are valid only when the two fractions refer to the same whole and record the results of comparisons with the symbols >, =, or \n",
      "\n",
      "similar phrases:\n",
      "[   (   140,\n",
      "        'compare two decimals to hundredths by reasoning about their size. '\n",
      "        'Recognize that comparisons are valid only when the two decimals refer '\n",
      "        'to the same whole. Record the results of comparisons with the symbols '\n",
      "        '>, =, or \\n',\n",
      "        0.9938489477098706),\n",
      "    (   128,\n",
      "        'compare two fractions with different numerators and different '\n",
      "        'denominators (e.g., by using virtual fraction models, by creating '\n",
      "        'common denominators or numerators, or by comparing to a benchmark '\n",
      "        'fraction such as 1/2); recognize that comparisons are valid only when '\n",
      "        'the two fractions refer to the same whole; record the results of '\n",
      "        'comparisons with symbols >, =, or \\n',\n",
      "        0.9701726943456401),\n",
      "    (   120,\n",
      "        'generate a number or shape pattern that follows a given rule. '\n",
      "        'Identify apparent features of the pattern that were not explicit in '\n",
      "        'the rule itself. Explain informally why the numbers will continue to '\n",
      "        'alternate in this way. For example, given the rule \"ADD 3\" and the '\n",
      "        'starting number 1, generate terms in the resulting sequence and '\n",
      "        'observe that the terms appear to alternate between odd and even '\n",
      "        'numbers.\\n',\n",
      "        0.965925393675244),\n",
      "    (   237,\n",
      "        'identify when two expressions are equivalent (e.g., when the two '\n",
      "        'expressions name the same number regardless of which value is '\n",
      "        'substituted into them)',\n",
      "        0.9658172983332373),\n",
      "    (   288,\n",
      "        'identify when two expressions are equivalent (e.g., when the two '\n",
      "        'expressions name the same number regardless of which value is '\n",
      "        'substituted into them)',\n",
      "        0.9658172983332373),\n",
      "    (   296,\n",
      "        'draw polygons in the coordinate plane given coordinates for the '\n",
      "        'vertices; use coordinates to find the length of a side joining points '\n",
      "        'with the same first coordinate or the same second coordinate; apply '\n",
      "        'these techniques in the context of solving real-world and '\n",
      "        'mathematical problems\\n',\n",
      "        0.964077759944806),\n",
      "    (   218,\n",
      "        'solve real world and mathematical problems by graphing points in all '\n",
      "        'four quadrants of the coordinate plane; include use of coordinates '\n",
      "        'and absolute value to find distances between points with the same '\n",
      "        'first coordinate or the same second coordinate',\n",
      "        0.9640743010772087),\n",
      "    (   280,\n",
      "        'solve real world and mathematical problems by graphing points in all '\n",
      "        'four quadrants of the coordinate plane; include use of coordinates '\n",
      "        'and absolute value to find distances between points with the same '\n",
      "        'first coordinate or the same second coordinate',\n",
      "        0.9640743010772087),\n",
      "    (   481,\n",
      "        'given two figures, use the definition of similarity in terms of '\n",
      "        'similarity transformations to decide if they are similar; explain '\n",
      "        'using similarity transformations the meaning of similarity for '\n",
      "        'triangles as the equality of all corresponding pairs of angles and '\n",
      "        'the proportionality of all corresponding pairs of sides\\n',\n",
      "        0.9639440209949671),\n",
      "    (   1034,\n",
      "        'given two figures, use the definition of similarity in terms of '\n",
      "        'similarity transformations to decide if they are similar; explain '\n",
      "        'using similarity transformations the meaning of similarity for '\n",
      "        'triangles as the equality of all corresponding pairs of angles and '\n",
      "        'the proportionality of all corresponding pairs of sides\\n',\n",
      "        0.9639440209949671)]\n"
     ]
    }
   ],
   "source": [
    "(phrase, phrase_scores) = get_similar_phrases(spacy_similarity, corpus, 100)\n",
    "print(\"phrase: %s\\nsimilar phrases:\" % phrase)\n",
    "pp.pprint(phrase_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase: compare two fractions with the same numerator or the same denominator by reasoning about their size; recognize that comparisons are valid only when the two fractions refer to the same whole and record the results of comparisons with the symbols >, =, or \n",
      "\n",
      "similar phrases:\n",
      "[   (   100,\n",
      "        'compare two fractions with the same numerator or the same denominator '\n",
      "        'by reasoning about their size; recognize that comparisons are valid '\n",
      "        'only when the two fractions refer to the same whole and record the '\n",
      "        'results of comparisons with the symbols >, =, or \\n',\n",
      "        3.078107524423501e-08),\n",
      "    (737, 'calculate acceleration vectors', 0.38898655014366695),\n",
      "    (685, 'evaluate improper integrals', 0.4491147117799509),\n",
      "    (554, 'compose functions', 0.4664251179671885),\n",
      "    (716, 'calculate dot products', 0.5218899415902706),\n",
      "    (910, 'solve optimization problems', 0.535102340901564),\n",
      "    (689, 'sketch curves in polar coordinates', 0.5402664260352563),\n",
      "    (1243, 'apply queuing theory', 0.5714449399353577),\n",
      "    (734, 'sketch curves defined by vectors', 0.5882803341976495),\n",
      "    (720, 'calculate cross products', 0.6052119827032579)]\n"
     ]
    }
   ],
   "source": [
    "(phrase, phrase_scores) = get_least_similar_phrases(spacy_similarity, corpus, 100)\n",
    "print(\"phrase: %s\\nsimilar phrases:\" % phrase)\n",
    "pp.pprint(phrase_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering documents based on topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_phrases(clusterer, topic_model, corpus):\n",
    "    cluster_model = clusterer.fit(topic_model)\n",
    "    cluster_topics = cluster_model.predict(topic_model)\n",
    "    score_clusters = cluster_model.transform(topic_model).min(axis=1)\n",
    "    clustered_corpus = [list(phrase) for phrase in zip(cluster_topics, corpus, score_clusters)]\n",
    "    return (cluster_model, clustered_corpus)\n",
    "\n",
    "def get_cluster_phrases(clustered_corpus, cluster_num):\n",
    "    phrases = [phrase for phrase in clustered_corpus if phrase[0] == cluster_num]\n",
    "    phrases_sorted = sorted(phrases, key=lambda t: t[2])[:10]\n",
    "    return phrases_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'calculate cross products', 0.18786611565908864],\n",
       " [1,\n",
       "  'solve word problems involving addition and subtraction of fractions referring to the same whole and having like denominators by using visual fraction models and equations to represent the problem',\n",
       "  0.20403922683109657],\n",
       " [1,\n",
       "  'distinguish among continuous, integer, and binary contexts',\n",
       "  0.21139554138869376],\n",
       " [1,\n",
       "  'solve word problems involving multiplication of a fraction by a whole number (e.g., by using visual fraction models and equations to represent the problem. For example, if each person at a party will eat 3/8 of a pound of roast beef and there will be 5 people at the party, how many pounds of roast beef will be needed? Between what two whole numbers does your answer lie?)\\n',\n",
       "  0.21487467576674626],\n",
       " [1,\n",
       "  'add, subtract, multiply and invert matrices choosing appropriate methods including technology',\n",
       "  0.22220867197355348],\n",
       " [1,\n",
       "  'apply the concepts of area, volume, scale factors, and scale drawings to planning for housing',\n",
       "  0.2775310519623051],\n",
       " [1,\n",
       "  'compare two sets of objects and identify which set is equal to, more than, or less than the other using matching and counting strategies',\n",
       "  0.30343686041337636],\n",
       " [1, 'add and subtract within 5 fluently', 0.3297207860771817],\n",
       " [1,\n",
       "  'use mental math strategies to add and subtract 10 or 100 to a given number between 100-900',\n",
       "  0.35569240810925756],\n",
       " [1,\n",
       "  'understand a fraction 1/b as the quantity formed by 1 part when a whole is partitioned into b equal parts (unit fraction); understand a fraction a/b as the quantity formed by a parts of size 1/b. For example, 3/4 means there are three 1/4 parts, so 3/4 = 1/4+1/4+1/4\\n',\n",
       "  0.36214432241408334]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans, kmeans_corpus = cluster_phrases(KMeans(n_clusters=50, random_state=0), lda_topics, corpus)\n",
    "get_cluster_phrases(kmeans_corpus, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\csgraph\\_laplacian.py:72: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if normed and (np.issubdtype(csgraph.dtype, int)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SpectralClustering' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-ec2d9fde8112>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspectral\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspectral_corpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcluster_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSpectralClustering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlda_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mget_cluster_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspectral_corpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-283aa2bbe686>\u001b[0m in \u001b[0;36mcluster_phrases\u001b[1;34m(clusterer, topic_model, corpus)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcluster_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclusterer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcluster_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclusterer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcluster_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcluster_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mscore_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcluster_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclustered_corpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SpectralClustering' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# need a spectral \"scoring function\"\n",
    "spectral, spectral_corpus = cluster_phrases(SpectralClustering(n_clusters=50, random_state=0), lda_topics, corpus)\n",
    "get_cluster_phrases(spectral_corpus, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmm, gmm_corpus = cluster_phrases(SpectralClustering(n_clusters=50, random_state=0), lda_topics, corpus)\n",
    "get_cluster_phrases(gmm, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbscan, dbscan_corpus = cluster_phrases(DBSCAN(eps=0.1, random_state=0), lda_topics, corpus)\n",
    "get_cluster_phrases(dbscan_corpus, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
